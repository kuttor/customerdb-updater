#!/usr/bin/env python

'''scrapenv

Usage:
    customerdb-update job <job_num> -u <username> -p <password>
    customerdb-update --help | --version 

Options:
    -h --help           Show this screen
    -v --version        Show version information
    -b --build-number   Input Jenkins job-number
    -u --username       Input Jenkins username
    -p --password       Input Jenkins password

'''
__author__ = 'Andrew Kuttor'
__email__ = 'andrew_kuttor@intuit.com'
__version__ = '1.0.0'

from docopt import DocoptExit, docopt
from bs4 import BeautifulSoup
from requests import get


# Extracts raw HTML date of the Jenkins env-var page
# Inputs: job number, Jenkins username and password
def scraped_html(job, usr, pwd):
    url = "http://pprddpsos400.corp.intuit.net:8080/job/" \
          "Pipeline%20-%20IDPS%20Operations/{}/injectedEnvVars/".format(job)

    html = get(url, auth=(usr, pwd))
    soup = BeautifulSoup(html.content, 'html.parser')

    return soup


# Parses scraped html data and converts to key/value dictionary
# Inputs: scraped/raw data
def to_dict(soup):
    list = [[
        cell.get_text().strip()
        for cell in row.find_all(['th', 'td'])]
        for row in soup.find_all('tr')]

    return list


def main():
    try:
        args = docopt(__doc__, version='CustomerDB-Update - v1.0')
        job = args['<job_num>']
        user = args['<username>']
        pssw = args['<password>']

        raw = scraped_html(job, user, pssw)
        print to_dict(raw)

    except DocoptExit as e:
        print(e.message)


# Let there be truth
if __name__ == "__main__":
    main()
